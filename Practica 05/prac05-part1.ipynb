{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Importació de llibreries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Llibreria per manipular dades a través d'una taula\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Parametrització dels conjunts d'entrenament i test\n",
    "Inicialitza dataset_dir amb el path del directori RedEdgeCompact"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "dataset_dir = \"C:/Users/Daniel/Downloads/RedEdgeCompact\"\n",
    "# === CONJUNT D'ENTRENAMENT =========================\n",
    "train_params = dict()\n",
    "train_params[\"path\"] = dataset_dir\n",
    "train_params[\"fields\"] = [\"000\", \"001\", \"002\", \"004\"];\n",
    "train_params[\"bands\"] = [\"R\",\"G\",\"B\", \"NIR\", \"RE\"]\n",
    "\n",
    "# === CONJUNT DE TEST ===============================\n",
    "test_params = dict()\n",
    "test_params[\"path\"] = dataset_dir\n",
    "test_params[\"fields\"] = [\"003\"]\n",
    "test_params[\"bands\"] = train_params[\"bands\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classes i funcions per carregar i manipular els datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Classe per accedir als retalls d'ortoimatge del dataset de manera indexada. S'obtenen les dades multiespectrals del retall indicat, així com la seva segmentació ground truth (imatge amb 4 bandes, cadascuna amb la máscara binària de cada classe: background, weed, crop, nodata)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    \"\"\" Llegeix imatges, i hi aplica transformacions d'augmentació i preprocés.\n",
    "\n",
    "    Args:\n",
    "        dataset: diccionari amb la informació per generar els conjunts d'entrenament\n",
    "                 a partir de la càrrega d'informació de disc.\n",
    "        bands: informació espectral a considerar en les imatges\n",
    "        mode: indica si es vol un dataset que retorni totes les imatges junte (\"complete\")\n",
    "              o bé la part a utilitzar en l'entrenament o la validació (\"training\" \"validation\")\n",
    "        augmentation (albumentations.Compose): pipeline de trandformació de les dades\n",
    "            (e.g. flip, scale, etc.)\n",
    "        preprocessing (albumentations.Compose): pipeline de preprocés de les dades\n",
    "            (e.g. normalització, canvis en el 'shape', etc.)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            dataset,\n",
    "            bands,\n",
    "            mode = \"complete\",\n",
    "            augmentation=None,\n",
    "            preprocessing=None,):\n",
    "\n",
    "        # Init directori structure organizing the weed map dataset\n",
    "        labels_dir = \"groundtruth\"\n",
    "        images_dir = \"tile\"\n",
    "        masks_dir = \"mask\"\n",
    "\n",
    "\n",
    "        # A partir de la informació del diccionari es defineixen els paths on buscar la informació\n",
    "        self.images_band_pattern = list()\n",
    "        self.labels = list()\n",
    "        self.masks = list()\n",
    "        for field in dataset[\"fields\"]:\n",
    "\n",
    "            images_path = os.path.join(dataset[\"path\"], \\\n",
    "                                     field, \\\n",
    "                                     images_dir);\n",
    "\n",
    "            labels_path = os.path.join(dataset[\"path\"], \\\n",
    "                                     field, \\\n",
    "                                     labels_dir);\n",
    "\n",
    "            masks_path = os.path.join(dataset[\"path\"], \\\n",
    "                                     field, \\\n",
    "                                     masks_dir);\n",
    "\n",
    "\n",
    "            # Per cada camp, el nom de les imatge a carregar s'extreun a partir\n",
    "            # del directori de màscares. Per cada imatge de màscara hi ha d'haver\n",
    "            # una imatge amb informació espectral corresponent.\n",
    "\n",
    "            images = sorted([f for f in os.listdir(masks_path) if not f.startswith('.')])\n",
    "\n",
    "            # Es genera una string de format que s'utilitzarà per després carregar\n",
    "            # la informació de les bandes de cada imatge\n",
    "\n",
    "            self.images_band_pattern = self.images_band_pattern +  \\\n",
    "                        [os.path.join(images_path, \"{band}\", image) \\\n",
    "                          for image in images]\n",
    "\n",
    "            # Es generen els noms complets per les imatges d'anotació (etiquetes GT)\n",
    "            self.labels = self.labels + \\\n",
    "                        [os.path.join(labels_path, \\\n",
    "                                      field+'_'+image.replace('.png','_GroundTruth_iMap.png') ) \\\n",
    "                          for image in images]\n",
    "\n",
    "            # Es generen els noms complets per les imatges de màscara. Indica els píxels\n",
    "            # pels que es té informació espectral o no (Hi ha zones molt grans de l'ortomapa\n",
    "            # per les que no es té informació).\n",
    "            self.masks = self.masks + \\\n",
    "                        [os.path.join(masks_path,image) \\\n",
    "                          for image in images]\n",
    "\n",
    "        # Depenent del mode seleccionat, l'objecte creat donarà accés a les ades completes o bé a\n",
    "        # un percentatge d'elles (70% si mode=\"training\", i el 30% complementari si mode=\"validation\")\n",
    "\n",
    "        if mode in [\"training\", \"validation\"]:\n",
    "\n",
    "            num_images = len(self.images_band_pattern)\n",
    "            training_percent = 0.7\n",
    "            # El generador de números aleatoris s'inicialitza a una llavor fixa, per així garantir que les\n",
    "            # versions \"training\" i \"test\" del dataseet són conjunts complementaris.\n",
    "            np.random.seed(0)\n",
    "            values = np.random.uniform(size=num_images)\n",
    "\n",
    "            if mode==\"training\":\n",
    "                selected_elements = (values<=training_percent)\n",
    "            elif mode==\"validation\":\n",
    "                selected_elements = (values>training_percent)\n",
    "\n",
    "            self.images_band_pattern = np.array(self.images_band_pattern)[selected_elements]\n",
    "            self.labels = np.array(self.labels)[selected_elements]\n",
    "            self.masks = np.array(self.masks)[selected_elements]\n",
    "\n",
    "            print(\"{} dataset preparat: {} de {} imatges seleccionades\".format(mode,np.sum(selected_elements),num_images))\n",
    "\n",
    "\n",
    "        elif mode!=\"complete\":\n",
    "            print(\"Mode {} desconegut. Es retorna el conjunt de dades complet\")\n",
    "\n",
    "        # L'anotació GT del weed map dataset distingeix 3 classes.\n",
    "        # class_codes 0: background, 2: weed, 10000: crop\n",
    "        # En realitat però n'hi ha 4. La máscara que indica els píxels que\n",
    "        # tenen dades permet etiquetar doncs els píxels que simplement no tenen\n",
    "        # dades, als que donarem l'etiqueta de \"nodata\", mentre en el dataset\n",
    "        # inicialment els posaven dins la classe \"background\"\n",
    "\n",
    "        self.class_names = [\"background\", \"weed\", \"crop\", \"nodata\"]\n",
    "        self.num_classes = len(self.class_names)\n",
    "\n",
    "        self.bands = bands\n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "\n",
    "    def __getitem__(self, i): # Retorna la imatge i la màscara del i-èssim element del dataset.\n",
    "        # Carrega la informació de les bandes de l'element 'i-èssim' del dataset\n",
    "\n",
    "        image_band_pattern = self.images_band_pattern[i]\n",
    "        band_list = []\n",
    "        for band in self.bands:\n",
    "            band_filename = image_band_pattern.format(band=band)\n",
    "            band_image = cv2.imread(band_filename, -cv2.IMREAD_LOAD_GDAL)\n",
    "            # Els valors dels píxels es normalitzen en el rang [0, 1]\n",
    "            band_image = band_image/255.0\n",
    "            band_list.append(band_image)\n",
    "\n",
    "        image = np.dstack(band_list)\n",
    "\n",
    "        # codec_labels: Anotació Ground truth de cada píxel de la imatge\n",
    "        coded_labels = cv2.imread(self.labels[i], -cv2.IMREAD_LOAD_GDAL)\n",
    "\n",
    "        # Les etiquetes dels píxels d'una imatge s'organitzen en una imatge\n",
    "        # multicanal, on cada canal és una máscara binaria que indica els\n",
    "        # píxels que formen part d'una determinada classe.\n",
    "\n",
    "        # El conjunt de dades \"Weedmap\" dataset distingeix 3 tipus de píxels\n",
    "        # a partir de 3 valors indicats a la imatge d'anotació GT, on cada\n",
    "        # valor denota la següent informació\n",
    "        # 0: background (inclou també els píxels que no tenen informació espectral\n",
    "        # 2: weed\n",
    "        # 10000: crop\n",
    "\n",
    "        # Es reformata la informació de ground truth, passant de tenir un valor numèric\n",
    "        # per cada classe a tenir una imatge binària per cada classe. Així, hi ha tantes\n",
    "        # màscares com classes diferents. Es guarden com a float per requisits de processos\n",
    "        # posteriors.\n",
    "        class_codes = [0, 2, 10000]\n",
    "        masks = [(coded_labels == code) for code in class_codes]\n",
    "        mask = np.stack(masks, axis=-1).astype('float')\n",
    "\n",
    "        # Per tractar millor les dades, es diferencia entre pixels 'background' del cultiu\n",
    "        # i píxels que simplement no tenen informació (pixels en tiles 'fora' de l'ortomapa)\n",
    "        # Això vol dir que:\n",
    "        #  Els píxels que no tenen informació espectral es treuen de la màscara background.\n",
    "        #  Es fa una nova màscara pels píxels que no tenen informació.\n",
    "\n",
    "        # Es llegeix la màscara que indica quins píxels tenen informació espectral\n",
    "\n",
    "        nodata_pixel_mask = cv2.imread(self.masks[i], -cv2.IMREAD_LOAD_GDAL).astype('float')/255.0\n",
    "\n",
    "        # S'ha vist que les imatges de máscara del dataset, en els píxels de les vores de la máscara a vegades\n",
    "        # indiquen que no hi ha informació en píxels on si hi ha informació, i que formen part de les\n",
    "        # classes weed i crop. Per tractar aquesta incoherència, es ralitza el següent:\n",
    "        # - En lloc de corregir la màscara nodata_pixel_mask (donaria força feina), ens asegurem que en\n",
    "        # els píxels de nodata_pixel_mask la resta de classes no tinguin un valor de '1' en la seva\n",
    "        # imaatge binària.\n",
    "        # - Afegim una classe més, que serà la desl píxels sense dades.\n",
    "        # Resolem la incoherència afegint però una mica de soroll, doncs en píxels on hi ha informació\n",
    "        # s'indica que la classe a predir és 'nodata', però a nivell percentual això és un número de píxels\n",
    "        # infim, de manera que d'entrada sembla assumible.\n",
    "\n",
    "        # Els pixels que segons la máscara no tenen dades no s'els permet ser \"background\", \"weed\" o \"crop\"...\n",
    "        mask[nodata_pixel_mask==1] = 0;\n",
    "        # ... si no que formen part d'una nova classe que anomenem \"nodata\".\n",
    "        mask = np.dstack((mask,nodata_pixel_mask))\n",
    "\n",
    "        # Si hi ha un funció de data augmentation, s'aplica tranformant tant la imatge com la màscara.\n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "\n",
    "        # Si hi ha una funció de proprocés s'aplica tranformant tant la imatge com la màscara\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "    def __len__(self):  # Retorna la quantitat d'imatges al dataset\n",
    "        return len(self.images_band_pattern)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Funció per mostrar per pantalla 'n' imatge rebudes com a paràmetre"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure()\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Establiment d'una mida de figura major per veure resultats per pantalla."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [12, 6]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Exemple d'accés i visualització d'un retall d'ortoimatge"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dataset = Dataset(train_params, train_params[\"bands\"])\n",
    "image, mask = train_dataset[1]\n",
    "visualize(\n",
    "    image=image[:,:,0:3],\n",
    "    background_mask=mask[:,:, 0],\n",
    "    weed_mask = mask[:,:, 1],\n",
    "    crop_mask = mask[:,:, 2],\n",
    "    nodata_mask = mask[:,:,3]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Funció per mostrar màscares de les classes com imatge a color\n",
    "\n",
    "Les diferents classes es mostren amb la següent convenció de colors\n",
    "* bakground: negre\n",
    "* weed: vermell\n",
    "* crop: verd\n",
    "* nodata: blau"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def generate_color_mask(mask):\n",
    "    color_mask = np.zeros((mask.shape[0],mask.shape[1],3))\n",
    "    color_mask[:,:,0] = mask[:,:,1]\n",
    "    color_mask[:,:,1] = mask[:,:,2]\n",
    "    color_mask[:,:,2] = mask[:,:,3]\n",
    "    return color_mask;"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "visualize( image=image[:,:,0:3],\n",
    "           labeled_image=generate_color_mask(mask))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Anàlisi dels estadístics del dataset\n",
    "Abans de desenvolupar un sistema de segmentació semàntica cal analitzar les dades de partida: quines bandes hi ha, com es distribueix el valor de cada banda segons la classe de cada píxel, etcètera."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Per facilitar aquest anàlisi, disposes de la següent funció que recull la informació dels píxels d'una quantitat d'imatges indicada en un DataFrame de pandas."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generate_df_from_dataset(dataset, num_images):\n",
    "    num_classes = dataset.num_classes;\n",
    "    class_names = dataset.class_names\n",
    "\n",
    "    # Es fa una selecció aleatòria d'imatges del dataset per analitzar els estadístics del dataset.dataset\n",
    "    # Si num_images és igual o major que el número d'imatges al datasets, és posa la informació del dataset\n",
    "    # sense en el DataFrame\n",
    "    selected_images = []\n",
    "    if num_images<len(dataset):\n",
    "        # S'estableix la llavor de números aleatoris, per obtenir el mateix resultat a cada execució\n",
    "        np.random.seed(0)\n",
    "        selected_images = np.random.randint(len(dataset), size=num_images)\n",
    "    else:\n",
    "        num_images = len(dataset)\n",
    "        selected_images = range(len(dataset))\n",
    "\n",
    "    print(\"Imatges al dataset:{} - Quantitat d'imatges analitzades aleatòriament:{}\".format(len(dataset),num_images))\n",
    "\n",
    "    # Es crea un diccionari d'arrays buits, per recollir la informació de les bandes de cada píxel, per cada classe.\n",
    "    # Cada fila dels arrays conté la informació de totes les bandes de cada píxel\n",
    "    band_values_per_class = dict.fromkeys(np.arange(num_classes),np.empty((0,len(dataset.bands)),dtype='float'))\n",
    "\n",
    "    start = time.time()\n",
    "    for i in tqdm(selected_images):\n",
    "\n",
    "        image, mask = dataset[i]\n",
    "\n",
    "        for j in range(mask.shape[-1]): # Per cadascuna de les classes anotades\n",
    "            # Per cada classe es recull la informació dels seus píxels\n",
    "            band_values_per_class[j] = np.vstack((band_values_per_class[j], image[mask[:,:,j]==1]))\n",
    "\n",
    "    # La informació delx píxels recollida s'utilitza per inicialitzar un DataFrame de panda\n",
    "    # per analitzar-lo amb les seves eines d'anàlisi i visualització. Per treure profit\n",
    "    # del funcionament de panda, s'afegeix una nova columna per cada píxel indicant la\n",
    "    # classe a la que pertany.\n",
    "\n",
    "    full_data = np.empty((0,len(dataset.bands)))\n",
    "    class_name_column = np.empty((0,1))\n",
    "    class_code_column = np.empty((0,1))\n",
    "    for i in range(num_classes):\n",
    "        full_data = np.vstack((full_data, \\\n",
    "                      band_values_per_class[i]))\n",
    "        num_samples_per_class = band_values_per_class[i].shape[0]\n",
    "\n",
    "        if num_samples_per_class>0:\n",
    "            class_name_column = np.vstack((class_name_column, \\\n",
    "                                   [[class_names[i]]]*num_samples_per_class))\n",
    "            class_code_column = np.vstack((class_code_column,\n",
    "                                           [[i]]*num_samples_per_class))\n",
    "\n",
    "    # The DataFrame is created, and an initial \"Class\" column is added\n",
    "    df = pd.DataFrame(full_data, columns =dataset.bands)\n",
    "    df.insert(0, \"Class\", class_name_column, True)\n",
    "    df.insert(0, \"Class_Code\", class_code_column, True)\n",
    "\n",
    "    end = time.time()\n",
    "    print(end - start)\n",
    "    print(\"Temps transcorregut per carregar les dades:{}\".format(end-start))\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "El següent codi obté el Dataframe per 'num_imatges' imatges aleatòries dels datasets d'entrenament i test."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_imatges = 50\n",
    "train_dataset = Dataset(train_params, train_params[\"bands\"])\n",
    "train_df = generate_df_from_dataset(train_dataset, num_imatges)\n",
    "\n",
    "test_dataset = Dataset(test_params, test_params[\"bands\"])\n",
    "test_df = generate_df_from_dataset(test_dataset, num_imatges)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 Anàlisi de la proporció dels píxels de cada classe\n",
    "Afegeix aquí el teu codi per processar el DataFrames generat a partir del mostreig del datasets. Mostra:\n",
    "* La quantitat i proporció de píxels de cada classe\n",
    "* El diagrama circular (pie plot) del dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Completa la següent funció\n",
    "def analisi_proporcio_classes(df):\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "analisi_proporcio_classes(train_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "analisi_proporcio_classes(test_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Repeteix l'anàlisi eliminant els píxels de tipus 'nodata' dels dataframes. No cal considerar aquests tipus de píxels perquè ja coneixem la seva classe a priori (el programa de generació de les ortoimatges ja ens dona la seva màscara). Per altra banda, la seva classificació és trivial (corresponen a píxels amb valor zero a totes les seves bandes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 Anàlisi de l’histograma dels píxels de cada cada classe\n",
    "Per analitzar si els diferents tipus de píxels són discriminable a partir d’una sola banda, a continuació visualitza el solapament dels seus histogrames a cada banda. Per realitzar aquest estudi, els bins a considerar en els histrogrames s’estableixen a continuació."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bins = (np.arange(0,255)-0.5)/255.0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2 Segmentació semàntica basada en la informació d'un píxel\n",
    "\n",
    "Analitza el rendiment de diferents classificadors 'clàssics' per discriminar entre píxels 'background', 'weed' i 'crop'.\n",
    "* Prova diferents alternatives (a la llibreria scikit-learn trobaràs múltiples algoritmes ja implementats, i fàcils de fer anar).\n",
    "* Identifica els algoritmes que van millor, i mira de millorar-ne el rendiment a partir d'ajustar els seus paràmetres.\n",
    "* A banda de les mètriques disponibles a scikit-learn, implementa les mètriques específiques per semantic segmentation que es comenten a l'enunciat de la pràctica."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "El següent codi extreu dels DataFrames els valors de 'x' (dades) i 'y' (etiqueta ground truth) que s'utilitzen a les funcions de scikit-learn per entrenar i avaluar classificadors (funcions fit, predict, classification_report, ...\n",
    "\n",
    "Es fa un mostreig de les dades disponible. En funció de les capacitats del teu ordinador pots augmentar o disminuir el valor de 'num_samples'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_samples = 5000\n",
    "sampled_train_df = train_df.sample(num_samples,random_state=0)\n",
    "sampled_test_df = test_df.sample(num_samples,random_state=0)\n",
    "\n",
    "selected_bands = train_params[\"bands\"]\n",
    "x_train = sampled_train_df[selected_bands].to_numpy()\n",
    "y_train = sampled_train_df[\"Class_Code\"].to_numpy()\n",
    "x_test = sampled_train_df[selected_bands].to_numpy()\n",
    "y_test = sampled_train_df[\"Class_Code\"].to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3 Anàlisi del rendiment a nivell d'imatge\n",
    "Per tenir una visió qualitativa del millor mètode identificat a la secció anterior, implementa una funció per aplicar-lo a tots els píxels d'una imatge del dataset, per obtenir la seva segmentació semàntica resultant.\n",
    "\n",
    "Utilitza les mètriques treballades a la secció anterior per identificar les 5 imatges del test_dataset on el classificador funciona millor, i les 5 imatges on el classificador funciona pitjor."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}